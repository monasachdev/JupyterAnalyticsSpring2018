{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "PSY 394U <b>Data Analytics with Python</b>, Spring 2018\n",
    "\n",
    "\n",
    "<img style=\"width: 400px; padding: 0px;\" src=\"https://github.com/sathayas/JupyterAnalyticsSpring2018/blob/master/images/Title_pics.png?raw=true\" alt=\"title pics\"/>\n",
    "\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align:center; font-size:40px; margin-bottom: 30px;\"><b> Text processing </b></p>\n",
    "\n",
    "<p style=\"text-align:center; font-size:18px; margin-bottom: 32px;\"><b>April 12, 2018</b></p>\n",
    "\n",
    "<hr style=\"height:5px;border:none\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Example text data\n",
    "<hr style=\"height:1px;border:none\" />\n",
    "\n",
    "To start out with **NLTK** (**Natural Language Toolkit**), we first download some example data available for NLTK. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<NLTKIntro.py>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# downloading example text corpora \"book\"\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should open a downloader window\n",
    "\n",
    "<img style=\"width: 600px; padding: 0px;\" src=\"https://github.com/sathayas/JupyterAnalyticsSpring2018/blob/master/images/nltk_downloader.png?raw=true\" alt=\"NLTK downloader\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the downloader, please download the collection **book**. It contains a number of corpora (plural of corpus) used in the [NLTK book](http://www.nltk.org/book/). A corpus is a collection of texts. It may take a few minutes to download this collection. It takes about 420MB of disk space on your computer. \n",
    "\n",
    "Now, let's take a look at the *Gutenberg corpus* (**`gutenberg`** under **`nltk.corpus`**). The *Gutenberg* corpus includes a number of literary works, and can be used as example data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading the Gutenberg corpus\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the content of this corpus by the **`fileids()`** method, which produces a list of files as part of this corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we will use Emma by Jane Austen (**`austen-emma.txt`**). We can simply load the raw text data with the **`raw`** method associated with the corpus `gutenberg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was t\n"
     ]
    }
   ],
   "source": [
    "# loading the raw text\n",
    "emmaRawText = gutenberg.raw('austen-emma.txt')\n",
    "print(emmaRawText[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can load as a collection of words using the **`words`** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty', '-', 'one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', 'She', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "# loading words\n",
    "emmaWords = gutenberg.words('austen-emma.txt')\n",
    "print(emmaWords[:80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Downloading some corpora\n",
    "* Example text\n",
    "* Tokenizing\n",
    "* Word frequency\n",
    "* Part of speech tagging\n",
    "* Stop words\n",
    "    * Word frequency before and after stop word removal\n",
    "* Stemming & lemmatizing \n",
    "* Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
